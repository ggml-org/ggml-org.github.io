<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <title>ggml.ai</title>

        <style>
            #main {
                margin-left: 10px;
                margin-right: 10px;
                margin-top: 40px;
                margin-bottom: 40px;
            }
            body { 
                max-width: 650px;
                line-height: 1.2;
                font-size: 16px;
                margin: 0 auto;
            }
            p, li {
                overflow-wrap: break-word;
                word-wrap: break-word;
                hyphens: auto;
                text-align: justify;
            }
            p {
                margin-top: 0.5em;
                margin-bottom: 0.5em;
            }
        </style>
    </head>
    <body>
        <div id="main">
            <h3>GGML - AI at the edge</h3>

            <p><a href="https://github.com/ggerganov/ggml"><b>ggml</b></a> is a tensor library for machine learning to enable large models and high performance on
                commodity hardware. It is used by <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> and
                <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a></p>

            <ul>
                <li>Low-level cross-platform implementation</li>
                <li>Integer quantization support</li>
                <li>Broad hardware support</li>
                <li>Automatic differentiation</li>
                <li>ADAM and L-BFGS optimizers</li>
                <li>No third-party dependencies</li>
                <li>Zero memory allocations during runtime</li>
            </ul>

            <h4>The <a href="https://github.com/ggerganov/ggml"><b>ggml</b></a> way</h4>

            <ul>
                <li>
                    <strong>Minimal</strong>
                    <p>We like simplicity and aim to keep the codebase as small and as simple as possible</p>
                </li>
                <li>
                    <strong>Open Core</strong>
                    <p>The library and related projects are freely available under the MIT license. The development
                        process is open and everyone is welcome to join. In the future we may choose to develop
                        extensions that are licensed for commercial use</p>
                </li>
                <li>
                    <strong>Explore and have fun!</strong>
                    <p>We built <a href="https://github.com/ggerganov/ggml"><b>ggml</b></a> in the spirit of play.
                        Contributors are encouraged to try crazy ideas, build wild demos, and push the edge of whatâ€™s
                        possible</p>
                </li>
            </ul>

            <h4>Projects</h4>

            <ul>
                <li>
                    <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a>

                    <p>High-performance inference of OpenAI's Whisper automatic speech recognition model</p>

                    <p>The project provides a high-quality speech-to-text solution that runs on Mac, Windows, Linux,
                        iOS, Android, Raspberry Pi, and Web</p>
                </li>
                <li>
                    <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>

                    <p>Inference of Meta's LLaMA large language model</p>

                    <p>The project demonstrates efficient inference on Apple Silicon hardware and explores a variety of
                        optimization techniques and applications of LLMs</p>
                </li>
            </ul>

            <h4>Contributing</h4>

            <ul>
                <li>
                    <p>The best way to support the project is by contributing to the codebase<p>
                </li>
                <li>
                    <p>If you wish to financially support the project, please consider becoming a sponsor to any of the
                        contributors that are already involved:</p>
                    <ul>
                        <li><a href="https://github.com/ggerganov/llama.cpp/graphs/contributors">llama.cpp contributors</a></li>
                        <li><a href="https://github.com/ggerganov/whisper.cpp/graphs/contributors">whisper.cpp contributors</a></li>
                        <li><a href="https://github.com/ggerganov/ggml/graphs/contributors">ggml contributors</a></li>
                    </ul>
                </li>
            </ul>

            <h4>Company</h4>

            <p><a href="https://ggml.ai">ggml.ai</a> is a company founded by <a
                  href="https://github.com/ggerganov">Georgi Gerganov</a> to support the development of <a
                  href="https://github.com/ggerganov/ggml"><b>ggml</b></a>. <a href="https://nat.org">Nat Friedman</a>
              and <a href="https://dcgross.com">Daniel Gross</a> provided the pre-seed funding.</p>

            <p>We are currently seeking to hire full-time developers that share our vision and would like to help
                advance the idea of on-device inference. If you are interested and if you have already been a
                contributor to any of the related projects, please contact us at jobs@ggml.ai </p>

            <h4>Business inquiries</h4>

            <p>For any business-related topics, including support or enterprise deployment, please contact us at
                sales@ggml.ai</p>
        </div>
    </body>
</html>
